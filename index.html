<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <title>Siyuan Li</title>
  <meta name="description" content="Siyuan Li's homepage">

  <link href="./css/github-light.css" rel="stylesheet">
  <link href="./css/style.css" rel="stylesheet">
</head>
<body>
  <div class="container">
    <header>
      <h1>Siyuan Li</h1>
      <img src="./assets/lsy.jpeg" style="width:230px;"><br />
      <p>
        <br/>
        Ph.D. in Computer Science <br />
        Deep Reinforcement Learning <br />
        @ Tsinghua University <br />
        <br/>
        <img src="./assets/4.png" alt="Beijing, China" style="width:19px;border:0;"> Beijing, China </a> <br/>
        <a href="mailto: sy-li17@mails.tsinghua.edu.cn"> <img src="./assets/email_icon.png" alt="Email" style="width:19px;border:0;"> Email </a> <br/>
        <a href="https://scholar.google.com/citations?user=hrBJWKAAAAAJ&hl=zh-CN"> <img src="./assets/ggscholar_black.png" alt="Google Scholar" style="width:16px;height:14px;border:0;"> Google Scholar </a> <br/>
        <a href="https://github.com/SiyuanLee"> <img src="./assets/github.png" alt="Github" style="width:16px;height:15px;border:0;"> Github </a> <br/>
    </header>

    <section class="content">
      <h3>About Me</h3>
      <p>
        I am a fourth-year Ph.D. candidate advised by <a href="http://people.iiis.tsinghua.edu.cn/~zhang/"> Prof. Chongjie Zhang </a> at <a href="https://iiis.tsinghua.edu.cn/en/">
        Institute for Interdisciplinary Information Sciences</a>, Tsinghua University, headed by <a href="https://iiis.tsinghua.edu.cn/yao/"> Prof. Andrew Yao</a>.
        My research interests include <b> Reinforcement Learning </b> and <b> Deep Learning </b>. My primary goal is to improve the sample efficiency of deep
        reinforcement learning via task decomposition, knowledge reuse, and efficient exploration.
      </p>

      <h3>Publications</h3>
      <ol class="sparse-list">
         <li>
          <span class="underline">Siyuan Li</span>*, Lulu Zheng*, Jianhao Wang, and Chongjie Zhang <br />
          <b style=color:#4169E1;">Learning Subgoal Representations with Slow Dynamics.</b> <br />
          <b>ICLR 2021: </b> The Ninth International Conference on Learning Representations <br/>
          <a href="https://openreview.net/pdf?id=wxRwhSdORKG"> PDF </a> | <a href="https://sites.google.com/view/lesson-iclr"> Video </a> | <a href="https://github.com/SiyuanLee/LESSON"> Code </a>
        </li>
        <li>
          <span class="underline">Siyuan Li </span> <br />
          <b style=color:#4169E1;">Deep Reinforcement Learning with Hierarchical Structures.</b> <br />
          <b>IJCAI DC 2021: </b> The Thirtieth International Joint Conference on Artificial Intelligence Doctoral Consortium <br/>
          <a> PDF </a>
        </li>
        <li>
          <span class="underline">Siyuan Li</span>*, Rui Wang*, Minxue Tang, and Chongjie Zhang <br />
          <b style=color:#4169E1;">Hierarchical Reinforcement Learning with Advantage-Based Auxiliary Rewards.</b> <br />
          <b>NeurIPS 2019: </b> Advances in Neural Information Processing Systems <br/>
          <a href="https://proceedings.neurips.cc/paper/2019/file/81e74d678581a3bb7a720b019f4f1a93-Paper.pdf"> PDF </a> | <a href="http://bit.ly/2JxA0eN"> Video </a> | <a href="https://github.com/ArayCHN/HAAR-A-Hierarchical-RL-Algorithm"> Code </a>
        </li>
         <li>
          <span class="underline">Siyuan Li</span>, Fangda Gu, Guangxiang Zhu, and Chongjie Zhang <br />
          <b style=color:#4169E1;">Context-Aware Policy Reuse.</b> <br />
          <b>AAMAS 2019 (Oral): </b> International Conference on Autonomous Agents and MultiAgent Systems <br/>
          <a href="https://arxiv.org/pdf/1806.03793.pdf"> PDF </a> | <a href="https://github.com/SiyuanLee/caps"> Code </a>
        </li>
        <li>
          <span class="underline">Siyuan Li</span> and Chongjie Zhang <br />
          <b style=color:#4169E1;">An Optimal Online Method of Selecting Source Policies for Reinforcement Learning.</b> <br />
          <b>AAAI 2018 (Spotlight): </b> The Thirty-Second AAAI Conference on Artificial Intelligence <br/>
          <a href="https://arxiv.org/abs/1709.08201"> PDF </a>
        </li>
        <li>
          <span class="underline">Siyuan Li</span>, Jin Zhang, Jianhao Wang, and Chongjie Zhang  <br />
          <b style=color:#4169E1;">Efficient Hierarchical Exploration with Stable Subgoal Representation Learning.</b> <br />
          Under Review, 2021 <br />
          <a href="https://arxiv.org/abs/2105.14750"> PDF </a>
        </li>
        <li>
          Jianhao Wang, Wenzhe Li, Haozhe Jiang, Guangxiang Zhu, <span class="underline">Siyuan Li</span>, and Chongjie Zhang <br />
          <b style=color:#4169E1;">Offline Reinforcement Learning with Reverse Model-based Imagination.</b> <br />
          Under Review, 2021 <br />
          <a > PDF </a>
        </li>
      </ol>

      <h3>Selected Awards</h3>
      <ol class="sparse-list">
        <li>
          Huawei Academic Excellence Award by Tsinghua University, 2020.
        </li>
        <li>
        Best Project Award by Google Machine Learning Winter Camp, 2020.
      </li>
        <li>
        <b>National Scholarship (top 1%) </b> for Graduate Students at Tsinghua University, 2019.
        </li>
        <li>
        Tsinghua Scholarship for Overseas Graduate Study, 2019.
      </li>
        <li>
        Baidu Future Star Excellent Award by Tsinghua University, 2018
      </li>
      </ol>

      <h3>Reviewer Activities</h3>
      <ul>
        <li><b> ICML 2021: </b> 38th International Conference on Machine Learning.</li>
        <li><b> ICLR 2021 <strong>Outstanding Reviewer Award</strong>: </b> 9th International Conference on Learning Representations.</li>
        <li><b> IJCAI 2021: </b> 30th International Joint Conference on Artificial Intelligence.</li>
        <li><b> NeurIPS 2020: </b> 34th Conference on Neural Information Processing Systems.</li>
        <li><b> IJCAI 2020: </b> 29th International Joint Conference on Artificial Intelligence.</li>
      </ul>

      <h3> Experience </h3>
      <ul>
        <li><b> Teaching Assistant: </b> Artificial Intelligence: Principles and Techniques, Fall, 2019 </li>
        <li><b> Teaching Assistant: </b> Deep Reinforcement Learning, Spring, 2020 </li>
        <li><b> Teaching Assistant: </b> Artificial Intelligence: Principles and Techniques, Fall, 2020 </li>
      </ul>

      <h3>Education</h3>
      <ul>
        <li>
          <b> M.Sc. in Computer Science (GPA: 3.92 / 4.00) </b> <br/>
          IIIS, Tsinghua University @ Beijing, China, 2018 -- Present <br/>
          Multi-Agent Reinforcement Learning
        </li>
        <li>
          <b> B.Sc. in Computer Science (GPA: 3.99 / 4.00) </b> <br/>
          Taishan Academy, Shandong University @ Shandong, China, 2014 -- 2018 <br/>
          Computer Vision, Augmented Reality, Multi-Agent Reinforcement Learning <br/>
          Thesis: Anonymous Hierarchical Multi-Agent Policy Gradients (with distinction)
        </li>
      </ul>
    </section>
  </div>
</body>
</html>
